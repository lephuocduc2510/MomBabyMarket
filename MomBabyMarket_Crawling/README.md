# MomBabyMarket CrawlerTool crawl chuyÃªn nghiá»‡p cho dá»± Ã¡n MomBabyMarket case study sá»­ dá»¥ng JavaScript vÃ  Docker.## ğŸš€ TÃ­nh nÄƒng- **Multi-platform**: Facebook, Instagram, E-commerce websites- **Docker containerized**: Deploy chuyÃªn nghiá»‡p vá»›i Docker- **Service Pattern**: Kiáº¿n trÃºc module rÃµ rÃ ng, dá»… báº£o trÃ¬- **Image downloading**: Tá»± Ä‘á»™ng download vÃ  tá»‘i Æ°u áº£nh- **Comprehensive logging**: Há»‡ thá»‘ng log chi tiáº¿t- **Error handling**: Xá»­ lÃ½ lá»—i vÃ  retry mechanism## ğŸ“‹ YÃªu cáº§u- Node.js 18+ (náº¿u cháº¡y local)- Docker & Docker Compose (khuyáº¿n nghá»‹)- 4GB+ RAM cho browser instances## ğŸ› ï¸ CÃ i Ä‘áº·t & Cháº¡y### Option 1: Docker (Khuyáº¿n nghá»‹)```bash# Navigate to projectcd MomBabyMarket_Crawling# CÃ i Ä‘áº·t dependenciesnpm install# Build vÃ  cháº¡y vá»›i Dockernpm run docker:buildnpm run docker:run# Xem logsnpm run docker:logs# Dá»«ng containersnpm run docker:stop```### Option 2: Local Development```bash# CÃ i Ä‘áº·t dependenciesnpm install# Táº¡o thÆ° má»¥c outputmkdir -p data/images logs# Cháº¡y development modenpm run dev# Hoáº·c cháº¡y productionnpm start```## âš™ï¸ Cáº¥u hÃ¬nh### Environment Variables (.env)```env# Crawler SettingsNODE_ENV=developmentHEADLESS=trueCRAWL_DELAY=3000MAX_RETRIES=3TIMEOUT=30000# Browser SettingsUSER_AGENT=Mozilla/5.0 (Windows NT 10.0; Win64; x64)...VIEWPORT_WIDTH=1366VIEWPORT_HEIGHT=768# Output SettingsOUTPUT_DIR=./dataIMAGES_DIR=./data/images# LoggingLOG_LEVEL=info```### Targets ConfigurationFile `src/config/targets.js` chá»©a 32 targets:- 16 Facebook pages- 6 Instagram accounts  - 10 E-commerce websites## ğŸ“Š Cáº¥u trÃºc Output```data/â”œâ”€â”€ crawled_data.json          # Dá»¯ liá»‡u chÃ­nhâ”œâ”€â”€ crawl_stats.json           # Thá»‘ng kÃª crawlâ”œâ”€â”€ summary_report.json        # BÃ¡o cÃ¡o tá»•ng há»£pâ””â”€â”€ images/                    # áº¢nh Ä‘Ã£ download    â”œâ”€â”€ facebook/    â”œâ”€â”€ instagram/    â””â”€â”€ website/```### Format dá»¯ liá»‡u JSON```json{  "title": "TiÃªu Ä‘á» bÃ i viáº¿t hoáº·c sáº£n pháº©m",  "content": "Ná»™i dung bÃ i viáº¿t (náº¿u cÃ³)",  "imageUrl": "URL áº£nh gá»‘c",  "localImagePath": "data/images/facebook/image.jpg",  "articleUrl": "https://facebook.com/post/123",  "publishedAt": "2025-01-15T10:30:00.000Z",  "source": "https://www.facebook.com/mamako.mgl/",  "platform": "facebook",  "crawledAt":# MomBabyMarket Crawler ğŸ•·ï¸

Tool crawl chuyÃªn nghiá»‡p cho dá»± Ã¡n MomBabyMarket case study. Thu tháº­p dá»¯ liá»‡u tá»« 32 targets: Facebook, Instagram vÃ  cÃ¡c website thÆ°Æ¡ng máº¡i Ä‘iá»‡n tá»­.

## ğŸš€ TÃ­nh nÄƒng

- âœ… **32 targets**: 16 Facebook + 6 Instagram + 10 websites  
- âœ… **Docker ready**: Containerized vá»›i Chrome headless
- âœ… **Service Pattern**: Kiáº¿n trÃºc modular, dá»… báº£o trÃ¬
- âœ… **Auto download**: Táº£i vÃ  tá»‘i Æ°u áº£nh tá»± Ä‘á»™ng
- âœ… **Error handling**: Retry mechanism + comprehensive logging

## ğŸ“‹ YÃªu cáº§u

- **Docker** (khuyáº¿n nghá»‹) hoáº·c Node.js 18+
- **4GB+ RAM** cho browser instances
- **Internet connection** á»•n Ä‘á»‹nh

## ğŸƒâ€â™‚ï¸ CÃ¡ch cháº¡y

### Option 1: Docker (Khuyáº¿n nghá»‹)

```bash
# 1. Build image
docker build -t mombabymarket-crawler .

# 2. Cháº¡y crawler
docker run mombabymarket-crawler
```

### Option 2: Docker vá»›i volume mapping

```bash
# Map data folder Ä‘á»ƒ lÆ°u káº¿t quáº£
docker run -v $(pwd)/data:/app/data mombabymarket-crawler

# Windows PowerShell:
docker run -v ${PWD}/data:/app/data mombabymarket-crawler

# Windows CMD:
docker run -v %cd%/data:/app/data mombabymarket-crawler
```

### Option 3: Local Development

```bash
# 1. CÃ i Ä‘áº·t dependencies
npm install

# 2. Cháº¡y crawler
npm start

# Debug mode
npm run dev
```

### Option 4: Docker Compose

```bash
# Build vÃ  cháº¡y
docker-compose up --build

# Cháº¡y background
docker-compose up -d

# Xem logs
docker-compose logs -f

# Dá»«ng
docker-compose down
```

## ğŸ”§ Debug & Troubleshooting

```bash
# Xem logs real-time
docker logs -f container_name

# VÃ o container Ä‘á»ƒ debug
docker run -it --entrypoint=/bin/sh mombabymarket-crawler

# Build láº¡i tá»« Ä‘áº§u
docker build --no-cache -t mombabymarket-crawler .

# Cháº¡y interactive mode
docker run -it mombabymarket-crawler
```

## ğŸ¯ 32 Targets

| Platform | Count | Examples |
|----------|-------|----------|
| Facebook | 16 | mamako.mgl, novomgl, pigeonmongolia... |
| Instagram | 6 | jivhkhurgelt, tushopping2, nominmn.official... |
| Websites | 10 | emonos.mn, jivh-hurgelt.mn, babyworld.mn... |

---

**Hekate Team** - Building AI-powered market intelligence ğŸš€"2025-01-15T12:00:00.000Z"}```## ğŸ—ï¸ Kiáº¿n trÃºc Service Pattern```src/â”œâ”€â”€ config/â”‚   â””â”€â”€ targets.js             # Cáº¥u hÃ¬nh 32 targetsâ”œâ”€â”€ services/â”‚   â”œâ”€â”€ browserService.js      # Quáº£n lÃ½ Puppeteer browserâ”‚   â”œâ”€â”€ imageService.js        # Download & optimize imagesâ”‚   â”œâ”€â”€ facebookCrawlerService.jsâ”‚   â”œâ”€â”€ instagramCrawlerService.jsâ”‚   â”œâ”€â”€ websiteCrawlerService.jsâ”‚   â”œâ”€â”€ fileService.js         # Save results to filesâ”‚   â””â”€â”€ crawlerService.js      # Main orchestratorâ”œâ”€â”€ utils/â”‚   â””â”€â”€ logger.js              # Winston loggingâ””â”€â”€ index.js                   # Entry point```## ğŸ¯ Platforms Ä‘Æ°á»£c há»— trá»£### Facebook Pages- Extract posts vá»›i titles, images, links- Dynamic content loading- Automatic scrolling### Instagram Accounts  - Crawl individual posts tá»« profile- Extract captions vÃ  images- Support posts vÃ  reels### E-commerce Websites- **emonos.mn**: Product listings- **jivh-hurgelt.mn**: Category-based crawling- **babyworld.mn**: Product information- **nomin.mn**: Articles vÃ  products## ğŸ”§ Advanced Usage### Custom Settings```bash# Crawl vá»›i headful mode (show browser)HEADLESS=false npm run dev# TÄƒng delay giá»¯a requestsCRAWL_DELAY=5000 npm start# Debug modeLOG_LEVEL=debug npm run dev```### Docker Commands```bash# Build custom imagedocker build -t my-crawler .# Run vá»›i custom settingsdocker run -e HEADLESS=false -v $(pwd)/data:/app/data my-crawler# Check logsdocker logs mombabymarket-crawler```## ğŸ“ˆ Performance & Monitoring- **Error handling**: Automatic retry vá»›i exponential backoff- **Rate limiting**: Built-in delays giá»¯a requests- **Memory management**: Proper browser cleanup- **Resource optimization**: Block CSS/fonts Ä‘á»ƒ tÄƒng tá»‘c## ğŸš€ Cháº¡y Crawler```bash# Development modenpm run dev# Production mode  npm start# Docker modenpm run docker:run```## ğŸ“ Output FilesSau khi cháº¡y, check cÃ¡c files:1. **`data/crawled_data.json`** - Dá»¯ liá»‡u chÃ­nh Ä‘á»ƒ import vÃ o MongoDB2. **`data/images/`** - áº¢nh Ä‘Ã£ download theo platform3. **`data/crawl_stats.json`** - Thá»‘ng kÃª performance4. **`logs/crawler.log`** - Log files chi tiáº¿t## ğŸ”„ Workflow tiáº¿p theo1. **Review results**: Check `data/crawled_data.json`2. **Validate images**: Verify áº£nh trong `data/images/`3. **Import to MongoDB**: Sá»­ dá»¥ng data cho Pháº§n 24. **API integration**: Connect tá»›i backend (Pháº§n 3)## ğŸ“„ LicenseMIT License---**Hekate Team** - Building the future of AI-powered market intelligence